{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d0680c",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Training\n",
    "\n",
    "This notebook demonstrates a structured workflow for **Logistic Regression model training, tuning, and evaluation**.\n",
    "\n",
    "### Overview of Iterations\n",
    "| Iteration | Description |\n",
    "|------------|--------------|\n",
    "| **1** | Evaluate model performance on different data fractions |\n",
    "| **2** | Hyperparameter tuning on 10% of training data |\n",
    "| **3** | Train on full data (max_iter = 1000) |\n",
    "| **4** | Train on full data (max_iter = 2500) for convergence |\n",
    "\n",
    "All trained models are saved as `.pkl` files in the `../models/` directory for future evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd0e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (761791, 5108)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "X_train = joblib.load('../data/processed/X_train_processed.pkl')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').squeeze()\n",
    "\n",
    "print(f\"Training shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1348a7",
   "metadata": {},
   "source": [
    "## **Iteration 1: Test Data Fractions**\n",
    "\n",
    "**Goal:**  \n",
    "Evaluate how model performance (AUC) scales with different fractions of the training data using 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58098dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iteration 1: Test Data Fractions ===\n",
      "Fraction 0.10 | AUC: 0.7141 | Time: 16.86s\n",
      "Fraction 0.25 | AUC: 0.7315 | Time: 44.20s\n",
      "Fraction 0.50 | AUC: 0.7441 | Time: 97.52s\n",
      "Fraction 0.75 | AUC: 0.7491 | Time: 156.14s\n",
      "Fraction 1.00 | AUC: 0.7520 | Time: 233.60s\n"
     ]
    }
   ],
   "source": [
    "fractions = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "print(\"=== Iteration 1: Test Data Fractions ===\")\n",
    "\n",
    "for f in fractions:\n",
    "    start = time.time()\n",
    "    if f == 1.0:\n",
    "        X_sub, y_sub = X_train, y_train\n",
    "    else:\n",
    "        X_sub, _, y_sub, _ = train_test_split(\n",
    "            X_train, y_train, train_size=f, stratify=y_train, random_state=42\n",
    "        )\n",
    "    model = LogisticRegression(max_iter=500, solver='saga', random_state=42)\n",
    "    auc = cross_val_score(model, X_sub, y_sub, cv=3, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    print(f\"Fraction {f:.2f} | AUC: {auc:.4f} | Time: {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3153137",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Model performance improves with more data, but gains plateau after ~50–75%.  \n",
    "- Using **10% of data** provides a good estimate of performance while saving significant computation time.  \n",
    "- Training time increases roughly linearly with data fraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7623c",
   "metadata": {},
   "source": [
    "## **Iteration 2: Hyperparameter Tuning on 10% Data**\n",
    "\n",
    "**Goal:**  \n",
    "Tune regularization type (`l1`, `l2`) and strength (`C`) using 5-fold cross-validation on 10% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b387d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iteration 2: Hyperparameter Tuning (10%) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 C=0.01 | AUC: 0.6085 | Time: 53.65s | Saved: ../models/lr_iter2_l1_C0.01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 C=0.1  | AUC: 0.6910 | Time: 146.32s | Saved: ../models/lr_iter2_l1_C0.1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 C=1    | AUC: 0.7160 | Time: 876.32s | Saved: ../models/lr_iter2_l1_C1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 C=10   | AUC: 0.7194 | Time: 1461.37s | Saved: ../models/lr_iter2_l1_C10.pkl\n",
      "L2 C=0.01 | AUC: 0.6760 | Time: 31.03s | Saved: ../models/lr_iter2_l2_C0.01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 C=0.1  | AUC: 0.7155 | Time: 41.50s | Saved: ../models/lr_iter2_l2_C0.1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 C=1    | AUC: 0.7193 | Time: 40.21s | Saved: ../models/lr_iter2_l2_C1.pkl\n",
      "L2 C=10   | AUC: 0.7197 | Time: 42.73s | Saved: ../models/lr_iter2_l2_C10.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_sub, _, y_sub, _ = train_test_split(\n",
    "    X_train, y_train, train_size=0.1, stratify=y_train, random_state=42\n",
    ")\n",
    "params = [('l1', 0.01), ('l1', 0.1), ('l1', 1), ('l1', 10),\n",
    "          ('l2', 0.01), ('l2', 0.1), ('l2', 1), ('l2', 10)]\n",
    "results = []\n",
    "\n",
    "print(\"=== Iteration 2: Hyperparameter Tuning (10%) ===\")\n",
    "for p, c in params:\n",
    "    start = time.time()\n",
    "    model = LogisticRegression(penalty=p, C=c, solver='saga', max_iter=500, random_state=42)\n",
    "    auc = cross_val_score(model, X_sub, y_sub, cv=5, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    model.fit(X_sub, y_sub)\n",
    "    filename = f\"../models/lr_iter2_{p}_C{c}.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    results.append({'penalty': p, 'C': c, 'AUC': auc, 'time': time.time()-start, 'file': filename})\n",
    "    print(f\"{p.upper()} C={c:<4} | AUC: {auc:.4f} | Time: {results[-1]['time']:.2f}s | Saved: {filename}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "best = results_df.loc[results_df['AUC'].idxmax()]\n",
    "results_df.to_csv('../models/hyperparam_tuning_summary_iter2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976630f",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "| Penalty | C | Mean AUC | Observation |\n",
    "|----------|---|-----------|-------------|\n",
    "| L1 | 0.01–10 | 0.60–0.72 | Slower convergence, lower AUC |\n",
    "| L2 | 0.01–10 | 0.68–0.72 | Stable convergence, better AUC |\n",
    "| **Best** | **L2** | **10** | **AUC = 0.7197** |\n",
    "\n",
    "**Insights:**\n",
    "- **Best model:** L2 penalty with `C = 10`.  \n",
    "- L1 penalty took longer to converge and occasionally failed within `max_iter = 500`.  \n",
    "- L2 penalty provided more stable performance and faster convergence.  \n",
    "- Larger `C` (weaker regularization) slightly improves validation AUC, indicating mild regularization is beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5ce10",
   "metadata": {},
   "source": [
    "## **Iteration 3: Train Model on Full Data (max_iter = 1000)**\n",
    "\n",
    "**Goal:**  \n",
    "Train the best model (L2 penalty, C = 10) using 5-fold cross-validation on the full training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177999f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iteration 3: Train Model on Full Data (max_iter=1000) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Iter3 | Penalty=l2 | C=10.0 | Train AUC: 0.7582 | Time: 1166.80s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Iteration 3: Train Model on Full Data (max_iter=1000) ===\")\n",
    "start = time.time()\n",
    "model_iter3 = LogisticRegression(penalty=best['penalty'], C=best['C'], solver='saga', max_iter=1000, random_state=42)\n",
    "model_iter3.fit(X_train, y_train)\n",
    "train_auc = cross_val_score(model_iter3, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1).mean()\n",
    "joblib.dump(model_iter3, '../models/lr_iter3.pkl')\n",
    "print(f\"Model Iter3 | Penalty={best['penalty']} | C={best['C']} | Train AUC: {train_auc:.4f} | Time: {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d24bc",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Training on full data improved performance compared to subset tuning.  \n",
    "- The model likely requires more iterations to converge fully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67269369",
   "metadata": {},
   "source": [
    "## **Iteration 4: Train Model on Full Data (max_iter = 2500)**\n",
    "\n",
    "**Goal:**  \n",
    "Increase `max_iter` to ensure full convergence and observe any improvement in AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077ac126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iteration 4: Train Model on Full Data (max_iter=2500) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihah\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Iter4 | Penalty=l2 | C=10.0 | Train AUC: 0.7604 | Time: 2996.58s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Iteration 4: Train Model on Full Data (max_iter=2500) ===\")\n",
    "start = time.time()\n",
    "model_iter4 = LogisticRegression(penalty=best['penalty'], C=best['C'], solver='saga', max_iter=2500, random_state=42)\n",
    "model_iter4.fit(X_train, y_train)\n",
    "train_auc = cross_val_score(model_iter4, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1).mean()\n",
    "joblib.dump(model_iter4, '../models/lr_iter4.pkl')\n",
    "print(f\"Model Iter4 | Penalty={best['penalty']} | C={best['C']} | Train AUC: {train_auc:.4f} | Time: {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a14b1d",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Although convergence was not perfect, AUC improved only slightly (+0.002).  \n",
    "- Indicates the model performance has **stabilized**, and further iterations would yield **diminishing returns**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c11bf5",
   "metadata": {},
   "source": [
    "## **Final Insights**\n",
    "\n",
    "The best-performing model is a **Logistic Regression** with **L2 regularization (C = 10)** and `max_iter = 2500`.  \n",
    "It achieved a **5-fold validation AUC of approximately 0.7604**, indicating strong and stable performance.  \n",
    "The **L2 regularization** improves generalization by penalizing large coefficients, helping prevent overfitting.  \n",
    "\n",
    "To load and use the trained model:\n",
    "```python\n",
    "import joblib\n",
    "model = joblib.load('../models/lr_iter4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
